{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.book import *\n",
    "import re, pprint\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "#from dateutil.parser import parse\n",
    "#import pattern3\n",
    "#from word2number import w2n\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datefinder\n",
    "import calendar\n",
    "import unicodedata\n",
    "import datetime\n",
    "import boto3\n",
    "import json\n",
    "import unidecode\n",
    "\n",
    "comprehend = boto3.client(service_name='comprehend', region_name='eu-west-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(sentence):#remove punctuation and \\n tokens\n",
    "##'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    punctuations = ['.',':',',',';','?'\n",
    "                    ,'!','/','[',']',\n",
    "                    '(',')','{','}','\"','-','|','`','^','~','<','>']\n",
    "    sentence = [w for w in sentence if w not in punctuations]\n",
    "#    sent=[w for w in sentence if w.isalnum()]##not effective\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops(sentence): #Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = [w for w in sentence if w not in stop_words]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_input):\n",
    "    sentences = sent_tokenize(raw_input)\n",
    "\n",
    "    sentences = [word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [remove_punct(sent) for sent in sentences]##remove punctuations\n",
    "    sentences = [remove_stops(sent) for sent in sentences]##remove stopwords\n",
    "    #Add pos_tag for sentences\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_numerals(sentence):\n",
    "    numbers_context = []\n",
    "    for w in range(0,len(sentence)):\n",
    "        ##Check for CD as POS tag of each word of the sentence\n",
    "        if sentence[w][1]=='CD':\n",
    "            ##push in context. Ensure the context exists irrespective of position of 'CD' within a sentence\n",
    "            if w > 1:\n",
    "                numbers_context.append(sentence[w-2])\n",
    "            if w > 0:\n",
    "                numbers_context.append(sentence[w-1])\n",
    "            numbers_context.append(sentence[w])\n",
    "            if w < len(sentence)-1:\n",
    "                numbers_context.append(sentence[w+1])\n",
    "            if w < len(sentence)-2:\n",
    "                numbers_context.append(sentence[w+2])\n",
    "    return numbers_context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 5##Context size is total\n",
    "def get_dates(numbers_in_context,raw_input):\n",
    "    only_words = []\n",
    "    month_list=calendar.month_name\n",
    "    counter = 0\n",
    "    is_a_date = []\n",
    "    all_dates = []\n",
    "    \n",
    "    for m in range(0,int(len(numbers_in_context)/CONTEXT_SIZE)+1):#for all candidate_dates\n",
    "        \n",
    "        if m==int(len(numbers_in_context)/CONTEXT_SIZE)+1:\n",
    "            context_list = numbers_in_context[m*CONTEXT_SIZE:-1]\n",
    "        else:\n",
    "            context_list = numbers_in_context[m*CONTEXT_SIZE:m*CONTEXT_SIZE+CONTEXT_SIZE]\n",
    "        \n",
    "        only_words = []\n",
    "        for w in range(0,len(context_list)):\n",
    "            only_words.append(context_list[w][0])\n",
    "            \n",
    "        list_of_wordContexts = \" \".join(str(x) for x in only_words)    \n",
    "        candidate_dates = list(datefinder.find_dates(list_of_wordContexts))\n",
    "        if not candidate_dates:\n",
    "            is_a_date.append(0)\n",
    "            all_dates.append(0)\n",
    "        else:\n",
    "            \n",
    "            for candid in candidate_dates:\n",
    "            #search for month_name / number in numbers_in_context of that sentence\n",
    "                match_year = re.search('\\\\s\\d{4}\\\\s', list_of_wordContexts)\n",
    "                if match_year:\n",
    "                    match_month = re.search('\\s+'+month_list[candid.month],list_of_wordContexts)                    \n",
    "                    if not match_month:\n",
    "                        match_month = re.search('\\s+\\d{2}\\s+', list_of_wordContexts)\n",
    "                        \n",
    "                        if not match_month:\n",
    "                            is_a_date.append(0)\n",
    "                            all_dates.append(candid)\n",
    "                        else:\n",
    "                            is_a_date.append(1)\n",
    "                            all_dates.append(candid)\n",
    "                    else:\n",
    "                        is_a_date.append(1)\n",
    "                        all_dates.append(candid)                        \n",
    "                else:    \n",
    "                    match_full = re.search('\\s+(\\d{2})(/|-)(\\d{2})(/|-|)\\d{4}\\s+',list_of_wordContexts)\n",
    "                    if not match_full:\n",
    "                            match_full = re.search('\\s+(\\d{2})(/|-)(\\d{2})(/|-|)\\d{2}\\s+',list_of_wordContexts)\n",
    "                            is_a_date.append(0)\n",
    "                            all_dates.append(0)\n",
    "                    else:  \n",
    "                        is_a_date.append(1) \n",
    "                        all_dates.append(candid)\n",
    "                        \n",
    "    return all_dates,is_a_date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./../data/d1.txt', './../data/d2.txt', './../data/d3.txt', './../data/d4.txt', './../data/d5.txt']\n",
      "**********Calling AWS Comprehend DetectEntities**********\n",
      "January 28, 2009\n",
      "March 5, 2002\n",
      "February 26, 2002\n",
      "March 5, 2002\n",
      "January 26, 2009\n",
      "January 26, 2009\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "November 18, 1920\n",
      "November, 1920\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "January 19, 1977\n",
      "November 14, 1985\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "7\n",
      "June 27, 1871\n",
      "June 27, 1871\n",
      "6\n",
      "January 19, 1977\n",
      "November 14, 1985\n",
      "June 27, 1871\n",
      "December 16, 1879\n",
      "June 27, 1871\n",
      "January 27, 1994\n",
      "4\n",
      "January 27, 1994\n",
      "March 9, 1995\n",
      "May 5, 1995\n",
      "May 25,\n",
      "1995\n",
      "May 31, 1995\n",
      "October 26, 1994\n",
      "*********End of AWS Comprehend DetectEntities********\n",
      "\n",
      "***********Calling Klassifai Contracts_InfoExtract_NLP******** \n",
      "2009-01-28 00:00:00\n",
      "2009-01-28 00:00:00\n",
      "2002-03-05 00:00:00\n",
      "2002-02-26 00:00:00\n",
      "2002-02-26 00:00:00\n",
      "2018-03-05 00:00:00\n",
      "2009-01-26 00:00:00\n",
      "2009-01-26 00:00:00\n",
      "2009-01-26 00:00:00\n",
      "2009-01-26 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1920-11-18 00:00:00\n",
      "1920-11-18 00:00:00\n",
      "1920-11-01 00:00:00\n",
      "1977-01-19 00:00:00\n",
      "1977-01-19 00:00:00\n",
      "2018-11-14 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1977-01-19 00:00:00\n",
      "1977-01-19 00:00:00\n",
      "2018-11-14 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1871-06-27 00:00:00\n",
      "1994-01-27 00:00:00\n",
      "1994-01-27 00:00:00\n",
      "1994-01-27 00:00:00\n",
      "1994-01-27 00:00:00\n",
      "1995-03-09 00:00:00\n",
      "1995-05-01 00:00:00\n",
      "2018-05-05 00:00:00\n",
      "1995-05-25 00:00:00\n",
      "1995-05-25 00:00:00\n",
      "1995-05-31 00:00:00\n",
      "1995-05-31 00:00:00\n",
      "1994-10-26 00:00:00\n",
      "1994-10-26 00:00:00\n",
      "*********End of Klassifai Contracts_InfoExtract_NLP********\n",
      "\n",
      "**********Calling AWS Comprehend DetectEntities**********\n",
      "2007\n",
      "Twelfth day of March\n",
      "2007\n",
      "2007\n",
      "1915\n",
      "1918\n",
      "1925\n",
      "1937\n",
      "1951\n",
      "1958\n",
      "1961\n",
      "1963\n",
      "1967\n",
      "1974\n",
      "1977\n",
      "1987\n",
      "1991\n",
      "1997\n",
      "2007\n",
      "10:38:33\n",
      "03/09/2012\n",
      "08/01/2012\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "2007\n",
      "March 8, 2012\n",
      "April 29, 2011\n",
      "2007\n",
      "2007\n",
      "March 8, 2012\n",
      "02/18/11\n",
      "04/08/11\n",
      "05-19-11\n",
      "March 3, 2012\n",
      "May 2011\n",
      "March 3, 2012\n",
      "March 3, 2012\n",
      "March 3, 2012\n",
      "*********End of AWS Comprehend DetectEntities********\n",
      "\n",
      "***********Calling Klassifai Contracts_InfoExtract_NLP******** \n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2011-04-29 15:00:00\n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2012-03-09 10:38:33\n",
      "2012-03-09 10:38:33\n",
      "2012-08-01 00:00:00\n",
      "2012-03-08 00:00:00\n",
      "2012-03-03 00:00:00\n",
      "2012-03-03 00:00:00\n",
      "2012-03-03 00:00:00\n",
      "2012-03-03 00:00:00\n",
      "*********End of Klassifai Contracts_InfoExtract_NLP********\n",
      "\n",
      "**********Calling AWS Comprehend DetectEntities**********\n",
      "March 31, 2015\n",
      "past 90 days\n",
      "May 8, 2015\n",
      "March 31, 2015\n",
      "December 30, 2014\n",
      "March 31, 2015\n",
      "2014\n",
      "March 31, 2015\n",
      "2014\n",
      "March 31\n",
      "2015\n",
      "December 31\n",
      "2014\n",
      "March 31, 2015\n",
      "December 31, 2014\n",
      "March 31, 2015\n",
      "July 28, 2000\n",
      "August 8, 2008\n",
      "March of 2012\n",
      "April 15, 2015\n",
      "next twelve months\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "July 28, 2000\n",
      "March of 2012\n",
      "2000\n",
      "past two years\n",
      "next 12 months\n",
      "next 6 months\n",
      "next year\n",
      "next twelve months\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "past two fiscal years\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "November 6, 2014\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "March 31, 2015\n",
      "May 12, 2015\n",
      "*********End of AWS Comprehend DetectEntities********\n",
      "\n",
      "***********Calling Klassifai Contracts_InfoExtract_NLP******** \n",
      "2015-05-08 00:00:00\n",
      "2015-03-31 20:14:00\n",
      "2015-03-31 20:14:00\n",
      "2015-03-31 20:14:00\n",
      "2015-03-31 20:14:00\n",
      "2000-07-28 00:00:00\n",
      "2000-07-28 00:00:00\n",
      "2008-08-08 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2000-07-28 00:00:00\n",
      "2000-07-28 00:00:00\n",
      "2008-08-08 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2014-11-06 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "2015-03-31 00:00:00\n",
      "*********End of Klassifai Contracts_InfoExtract_NLP********\n",
      "\n",
      "**********Calling AWS Comprehend DetectEntities**********\n",
      "March 12, 2016\n",
      "March 12, 2016\n",
      "March 15, 2016\n",
      "*********End of AWS Comprehend DetectEntities********\n",
      "\n",
      "***********Calling Klassifai Contracts_InfoExtract_NLP******** \n",
      "2016-03-12 00:00:00\n",
      "2016-03-12 00:00:00\n",
      "2016-03-15 00:00:00\n",
      "*********End of Klassifai Contracts_InfoExtract_NLP********\n",
      "\n",
      "**********Calling AWS Comprehend DetectEntities**********\n",
      "January 8, 2011\n",
      "March 1, 2015\n",
      "March 1, 2016\n",
      "February 25, 2015\n",
      "February 25, 2015\n",
      "*********End of AWS Comprehend DetectEntities********\n",
      "\n",
      "***********Calling Klassifai Contracts_InfoExtract_NLP******** \n",
      "2011-01-08 00:00:00\n",
      "2015-02-25 00:00:00\n",
      "*********End of Klassifai Contracts_InfoExtract_NLP********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rootdir = \"./../data/*.txt\"\n",
    "file_list = glob.glob(rootdir)\n",
    "print(file_list)\n",
    "\n",
    "if file_list:\n",
    "    for file_count in range(0,len(file_list)):\n",
    "        f= open(file_list[file_count],'r')\n",
    "        raw_input = f.read()\n",
    "        raw_input = re.sub(r'\\n{2,}', '.\\n',raw_input).strip()\n",
    "        sentences_aws = sent_tokenize(raw_input)\n",
    "        \n",
    "        print('**********Calling AWS Comprehend DetectEntities**********')\n",
    "        aws_name = os.path.splitext(file_list[file_count])[0]+'_AWS_out.json'  \n",
    "        with open(aws_name) as f:\n",
    "            output_dump = json.load(f)        \n",
    "        \n",
    "        all_dates = []\n",
    "        count=0\n",
    "        f = \"%B %d, %Y\"\n",
    "        for x in output_dump:\n",
    "            for i in range(0,len(output_dump[x][\"Entities\"])):\n",
    "                if output_dump[x][\"Entities\"][i][\"Type\"]==\"DATE\":\n",
    "                    #print(unidecode.unidecode(output_dump[x][\"Entities\"][i][\"Text\"]))\n",
    "\n",
    "                    dates_extracted=unidecode.unidecode(output_dump[x][\"Entities\"][i][\"Text\"])\n",
    "                    list_of_wordContexts = \"\".join(str(x) for x in dates_extracted)\n",
    "                    print(list_of_wordContexts)\n",
    "                    candidate_dates = list(datefinder.find_dates(list_of_wordContexts))\n",
    "                    for candid in candidate_dates:\n",
    "                        #print(candid)\n",
    "                        all_dates.append(candid)\n",
    "\n",
    "                    \n",
    "#                     new_date=datetime.datetime.strptime(dates_extracted,f).strftime('%m-%d-%Y')\n",
    "#                     print(new_date)\n",
    "#                     all_dates.append(new_date)\n",
    "        print('*********End of AWS Comprehend DetectEntities********\\n')\n",
    "\n",
    "        print('***********Calling Klassifai Contracts_InfoExtract_NLP******** ')\n",
    "        sentences = preprocess(raw_input)\n",
    "        numbers_in_context = [get_all_numerals(sent) for sent in sentences]\n",
    "        for sent in sentences:\n",
    "            numbers_in_context = get_all_numerals(sent)\n",
    "            candidate_dates,is_a_date = get_dates(numbers_in_context,sent)\n",
    "#            if file_count==1:\n",
    "            for d in range(0,len(is_a_date)):\n",
    "                if is_a_date[d]:\n",
    "                    print(candidate_dates[d])        \n",
    "        print('*********End of Klassifai Contracts_InfoExtract_NLP********\\n')\n",
    "                \n",
    "if not file_list:\n",
    "    print(\"Not finding list. Pls check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
